{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as p\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, TensorDataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "Load the datasets 'train images', 'train labels', 'test images', and 'test labels' that have been downloaded and saved in ./datasets. The dataset is a sub-dataset of MNIST including 28*28 greyscale images of handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(data_dir):\n",
    "    train_data_path = os.path.join(data_dir, 'train-images.idx3-ubyte')\n",
    "    train_labels_path = os.path.join(data_dir, 'train-labels.idx1-ubyte')\n",
    "    test_data_path = os.path.join(data_dir, 't10k-images.idx3-ubyte')\n",
    "    test_labels_path = os.path.join(data_dir, 't10k-labels.idx1-ubyte')\n",
    "\n",
    "\n",
    "    # Load training images\n",
    "    with open(train_data_path, 'rb') as f:\n",
    "        magic, num_images, rows, cols = np.fromfile(f, dtype=np.dtype('>i4'), count=4)\n",
    "        train_data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "\n",
    "    # Load training labels\n",
    "    with open(train_labels_path, 'rb') as f:\n",
    "        magic, num_labels = np.fromfile(f, dtype=np.dtype('>i4'), count=2)\n",
    "        train_labels = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "    # Load test images\n",
    "    with open(test_data_path, 'rb') as f:\n",
    "        magic, num_images, rows, cols = np.fromfile(f, dtype=np.dtype('>i4'), count=4)\n",
    "        test_data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "\n",
    "    # Load test labels\n",
    "    with open(test_labels_path, 'rb') as f:\n",
    "        magic, num_labels = np.fromfile(f, dtype=np.dtype('>i4'), count=2)\n",
    "        test_labels = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "    train_mean = np.mean(train_data / 255.)\n",
    "    print('train mean', train_mean)\n",
    "    train_std=np.std(train_data / 255.)\n",
    "    print('train std', train_std)\n",
    "\n",
    "    # Convert images to torch tensors and apply augmentation transforms\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        #transforms.RandomCrop(28, padding=4),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # Normalizing the test images\n",
    "    transform_test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "   \n",
    "    train_data = torch.stack([transform_train(img) for img in train_data])\n",
    "    test_data = torch.stack([transform_test(img) for img in test_data])\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset'\n",
    "train_images, train_labels, test_images, test_labels = load_mnist_data(dataset_path)\n",
    "\n",
    "#print shapes of train_images, train_labels, test_images, test_labels\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "\n",
    "# Create DataLoader objects for images and labels\n",
    "train_images_dataset = TensorDataset(train_images, torch.tensor(train_labels, dtype=torch.long))\n",
    "test_images_dataset = TensorDataset(test_images, torch.tensor(test_labels, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_images_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_images_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "First model to try is a 3 layer neural network model with ReLU activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "class DigitClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.Sigmoid(),\n",
    "            # nn.ReLU(True),\n",
    "            nn.Linear(64, 32),\n",
    "            # nn.ReLU(True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        # input layer\n",
    "    ##    self.all_layers.add_module('input', torch.nn.Linear(num_features, neurons_per_layer))\n",
    "      ##  self.all_layers.add_module('input_activation', activation_function)\n",
    "\n",
    "        # hidden layers\n",
    "      ##  for i in range(numbers_of_layers):\n",
    "      ##      self.all_layers.add_module(f'hidden_{i}', torch.nn.Linear(neurons_per_layer, neurons_per_layer))\n",
    "      ##      self.all_layers.add_module(f'hidden_{i}_activation', activation_function)\n",
    "\n",
    "        # output layer\n",
    "     ##   self.all_layers.add_module('output', torch.nn.Linear(neurons_per_layer, num_classes))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input image\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.classifier(x)    \n",
    "        return x\n",
    "    \n",
    "# the model\n",
    "#grey scale, num_channel=1\n",
    "model = DigitClassifier(28*28*1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model to try is a mobilenetV2. MobileNetV2 is an improvement over the original MobileNet architecture, introduced in the paper \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" by Sandler et al. It introduces inverted residuals with linear bottlenecks and other architectural changes to improve the efficiency and performance of MobileNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######ignore for now ###########\n",
    "import torchvision.models as models\n",
    "class ModifiedMobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedMobileNetV2, self).__init__()\n",
    "        self.mobilenet = mobilenet_v2(pretrained=False)\n",
    "        self.mobilenet.features[0][0] = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.resize = Resize((224, 224)) \n",
    "        # Modify the classifier\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1280, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "    \n",
    "model = ModifiedMobileNetV2(num_classes=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third model to try\n",
    "#4 layers cnn with ReLU activation\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  \n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature maps for the fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "def validate(dataloader: DataLoader, model: torch.nn.Module, loss_fn: torch.nn.Module):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0  # Initialize total loss for each epoch\n",
    "    num_batches = 0  # Initialize the number of batches processed\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            out = model(images)\n",
    "            loss = loss_fn(out, labels)\n",
    "            total_loss += loss.item()  # Accumulate total loss for the epoch\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    # val_loss.append(avg_loss)\n",
    "    return avg_loss\n",
    "    \n",
    "\n",
    "#add some more measurements here: accuracy, confusion matrix, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training loop\n",
    "learning_rate = 0.0001\n",
    "\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(555)\n",
    "\n",
    "# dimension n of the n*n input MNIST image\n",
    "n = 28\n",
    "\n",
    "# number of classes (digits 0-9)\n",
    "num_classes = 10\n",
    "eval_every = 1\n",
    "\n",
    "\n",
    "# loss and optimizer, try other combos too?\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#also try Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# train!\n",
    "num_epochs = 50   #increase this to at least 50\n",
    "epoch_losses = [] # to plot the loss curve later\n",
    "val_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        #use this version for mobilenet\n",
    "        images_rgb = torch.cat((images, images, images), dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        #print(\"Shape of target tensor:\", labels.shape)\n",
    "        #print(logits.shape)\n",
    "        loss = loss_fn(logits, labels) # Loss function\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % eval_every == 0:\n",
    "            validate_loss= validate(test_loader, model, loss_fn)\n",
    "            print(f\"epoch: {epoch}, validate loss: {validate_loss:.2f}\")\n",
    "            val_loss.append(validate_loss)\n",
    "    # logging + save the loss\n",
    "    print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\" f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\" f\" | Train Loss: {loss:.2f}\")\n",
    "    epoch_losses.append(loss)\n",
    "\n",
    "\n",
    "# save model after training\n",
    "torch.save(model.state_dict(), './model_nn_adam_0510.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_losses)\n",
    "print(len(epoch_losses))\n",
    "# training loss plot\n",
    "plt.plot([loss.detach().numpy() for loss in epoch_losses])\n",
    "plt.legend([\"Training Loss\"])\n",
    "plt.title(\"Training Loss vs. Number of Epoch\")\n",
    "plt.xlabel(\"Number of Epoch\")\n",
    "plt.ylabel(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss)\n",
    "print(len(val_loss))\n",
    "plt.plot(val_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss vs. Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
